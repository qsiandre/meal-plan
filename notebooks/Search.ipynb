{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1403923-82f5-4bc2-92e8-75c248b102b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e960de-0919-4b82-9991-c5fd11cfb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mysql.connector as connection\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    mydb = connection.connect(\n",
    "        host=os.environ.get(\"db_host\"),\n",
    "        database=os.environ.get(\"db_name\"),\n",
    "        user=os.environ.get(\"db_user\"),\n",
    "        passwd=os.environ.get(\"db_password\"),\n",
    "        use_pure=True,\n",
    "    )\n",
    "    query = \"\"\"\n",
    "    with latest_recipes as (\n",
    "        select url as latest_url, max(id) as latest_id \n",
    "        from dim_recipes \n",
    "        group by url\n",
    "    )\n",
    "    select id, ds, url, type, description, directions, ingredients, tags, title, image, serves, time, host \n",
    "    from dim_recipes \n",
    "    right join latest_recipes as lts \n",
    "    on lts.latest_id = dim_recipes.id\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, mydb)\n",
    "    print(df)\n",
    "    mydb.close()  # close the connection\n",
    "    \n",
    "except Exception as e:\n",
    "    mydb.close()\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d9f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c44577",
   "metadata": {},
   "outputs": [],
   "source": [
    "'A'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767293b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokenize(sentence): \n",
    "  return sentence.lower().split(' ')\n",
    "\n",
    "def clean_token(token):\n",
    "  m = re.match(\"^([a-z].*[a-z])$\", token)\n",
    "  return m.group(0) if m != None else None\n",
    "\n",
    "def valid_tokens(sentence):\n",
    "  tokens = tokenize(sentence)\n",
    "  valid = []\n",
    "  for tk in tokens:\n",
    "    clean = clean_token(tk)\n",
    "    if clean:\n",
    "      valid.append(clean)\n",
    "  return valid\n",
    "\n",
    "def get_entry(id):\n",
    "  matches = list(df[df['id'] == id].iterrows())\n",
    "  if len(matches) == 1:\n",
    "    return matches[0][1]\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "inv_index = {}\n",
    "for index, row in df.iterrows():\n",
    "  id = row['id']\n",
    "  tokens = valid_tokens(row['title'])\n",
    "  for tag in json.loads(row['tags']):\n",
    "    for token in valid_tokens(tag):\n",
    "      tokens.append(token)\n",
    "\n",
    "  for token in tokens:\n",
    "    values = inv_index[token] if token in inv_index else []\n",
    "    values.append(id)\n",
    "    inv_index[token] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c7ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Features:\n",
    "    def __init__(self, title):\n",
    "        self.matches = 0\n",
    "        self.title = title\n",
    "        self.ingredient_matches = 0\n",
    "        self.tag_matches = 0\n",
    "        self.description_matches = 0\n",
    "        self.direction_matches = 0\n",
    "\n",
    "    def get_key(self):\n",
    "        return (\n",
    "            self.matches,\n",
    "            self.tag_matches,\n",
    "            self.ingredient_matches,\n",
    "            self.description_matches,\n",
    "            self.direction_matches,\n",
    "            self.title,\n",
    "        )\n",
    "\n",
    "def get_features(entry, entries, query_tokens):\n",
    "    id = entry[\"id\"]\n",
    "    features = Features(entry[\"title\"])\n",
    "    for _, v in entries.items():\n",
    "        features.matches += 1 if id in v else 0\n",
    "\n",
    "    for tk in valid_tokens(entry[\"description\"]):\n",
    "        if tk in query_tokens:\n",
    "            features.description_matches += 1\n",
    "\n",
    "    for tag in json.loads(entry[\"tags\"]):\n",
    "        for tk in valid_tokens(tag):\n",
    "            if tk in query_tokens:\n",
    "                features.tag_matches += 1\n",
    "\n",
    "    for ingredient in json.loads(entry[\"ingredients\"]):\n",
    "        for tk in valid_tokens(ingredient):\n",
    "            if tk in query_tokens:\n",
    "                features.ingredient_matches += 1\n",
    "    for direction in json.loads(entry[\"directions\"]):\n",
    "        for tk in valid_tokens(direction):\n",
    "            if tk in query_tokens:\n",
    "                features.direction_matches += 1\n",
    "    return features\n",
    "\n",
    "def likely(prefix):\n",
    "    opts = []\n",
    "    for k, v in inv_index.items():\n",
    "        if k not in ('or', 'the', 'this') and k.startswith(prefix):\n",
    "            opts.append((k, len(v)))\n",
    "    opts.sort(reverse=True, key=lambda e: (e[1], -len(e[0]), e[0]))\n",
    "    return opts\n",
    "\n",
    "def search(query):\n",
    "    query_tokens = valid_tokens(query)\n",
    "    extended = [\n",
    "        lk\n",
    "        for (lk, _) in likely(query_tokens[-1])[:3]\n",
    "    ]\n",
    "    with_features = []\n",
    "    for ext in extended + [None]: \n",
    "        entries = {}\n",
    "        ids = set()\n",
    "        tokens = query_tokens + [ext]\n",
    "        for token in tokens:\n",
    "            if token in ('or', 'the', 'this'):\n",
    "                continue\n",
    "            values = (\n",
    "                inv_index[token]\n",
    "                if token in inv_index else []\n",
    "            )\n",
    "            entries[token] = set(values)\n",
    "            for id in values:\n",
    "                ids.add(id)\n",
    "        for id in ids:\n",
    "            entry = get_entry(id)\n",
    "            features = get_features(entry, entries, tokens)\n",
    "            with_features.append((entry, ext, features.get_key()))\n",
    "    with_features.sort(reverse=True, key=lambda e: (e[2], -len(e[1]) if e[1] else 0))\n",
    "    filtered = []\n",
    "    used = set()\n",
    "    for (entry, ext, f) in with_features:\n",
    "        if entry['id'] in used:\n",
    "            continue\n",
    "        used.add(entry['id'])\n",
    "        filtered.append((entry, ext, f))\n",
    "\n",
    "    return filtered, query_tokens\n",
    "\n",
    "result, tokens = search(\"bowl beef\")\n",
    "tokens, [((r[0][\"title\"], r[0][\"tags\"]), r[1], r[2]) for r in result], len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebff326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "likely(\"te\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
